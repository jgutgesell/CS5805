{
  "hash": "2567dd1290d84edf322000718e86619e",
  "result": {
    "markdown": "---\ntitle: \"Classification\"\nauthor: \"Julia Gutgesell\"\ndate: \"2023-11-19\"\ncategories: [news, code, analysis]\n---\n\n\nUnlike clustering which is an unsupervised technique, meaning that there are not labels or classes on the data, classification is the process of assigning data points to one of the predetermined classes given.\n\n![](classification.png)\n\nOne type of clustering algorithm is **Decision Trees**, which learn decision rules from data features to build a tree that can be followed to determine the chosen class for a new data point. It uses if-then rules to determine what action to take at a specific node/situation. \n\n![](tree.png)\n**Iris Example**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(222)\nindex <- sample(2, nrow(iris), replace = TRUE, prob = c(0.7, 0.3))\ntrain <- iris[index==1,]\ntest <- iris[index==2,]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tree)\n\nirisTree <- tree(Species ~ ., data = train)\nplot(irisTree, lwd = 2)\ntext(irisTree, cex = 0.7)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_frame_iris <- data.frame(test, prediction = predict(irisTree, test, type = \"class\"))\n\nlibrary(caret)\n(train_tab = table(predict_frame_iris$Species, predict_frame_iris$prediction))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             setosa versicolor virginica\n  setosa         18          0         0\n  versicolor      0         15         0\n  virginica       0          3        13\n```\n:::\n\n```{.r .cell-code}\ntrain_con_mat = confusionMatrix(train_tab, positive = \"setosa\")\ntrain_con_mat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            \n             setosa versicolor virginica\n  setosa         18          0         0\n  versicolor      0         15         0\n  virginica       0          3        13\n\nOverall Statistics\n                                          \n               Accuracy : 0.9388          \n                 95% CI : (0.8313, 0.9872)\n    No Information Rate : 0.3673          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9081          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            0.8333           1.0000\nSpecificity                 1.0000            1.0000           0.9167\nPos Pred Value              1.0000            1.0000           0.8125\nNeg Pred Value              1.0000            0.9118           1.0000\nPrevalence                  0.3673            0.3673           0.2653\nDetection Rate              0.3673            0.3061           0.2653\nDetection Prevalence        0.3673            0.3061           0.3265\nBalanced Accuracy           1.0000            0.9167           0.9583\n```\n:::\n:::\n\n\n\n**Random Forest**\n\nDecision Trees tend to overfit the data which can lead to a worse out of sample performance. To avoid this problem we can use a specific type of tree algorithm a **Random Forest**. Random Forest, like the name suggests, use many samples of the data and form a decision tree on each sample making a \"forest\" of many trees which are averaged to form the final model. Because of the many samples and averaging, the model is less prone to overfitting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\n\nrandomforest <- randomForest(Species~., data=train, proximity=TRUE)\n\np2 <- predict(randomforest, test)\nconfusionMatrix(p2, test$Species)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         18          0         0\n  versicolor      0         15         3\n  virginica       0          0        13\n\nOverall Statistics\n                                          \n               Accuracy : 0.9388          \n                 95% CI : (0.8313, 0.9872)\n    No Information Rate : 0.3673          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9081          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            1.0000           0.8125\nSpecificity                 1.0000            0.9118           1.0000\nPos Pred Value              1.0000            0.8333           1.0000\nNeg Pred Value              1.0000            1.0000           0.9167\nPrevalence                  0.3673            0.3061           0.3265\nDetection Rate              0.3673            0.3061           0.2653\nDetection Prevalence        0.3673            0.3673           0.2653\nBalanced Accuracy           1.0000            0.9559           0.9062\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(randomforest)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}