{
  "hash": "adf959d6c940cfe5f114d73417e202f4",
  "result": {
    "markdown": "---\ntitle: \"Clustering\"\nauthor: \"Julia Gutgesell\"\ndate: \"2023-11-18\"\ncategories: [news, code, analysis]\nimage: \"image.jpg\"\n---\n\n\nClustering is an unsupervised learning method that divides data points into a number of groups based on similar properties. There are multiple different clustering methods vary in the distance calculations to determine the clusters. Some of these algorithms are:\n-K-Means\n-Affinity Propagation\n-Mean-Shift\n-DBSCAN\n-Gaussian Mixtures\n-Spectral Clustering\n\nWe will focus on DBSCAN - Density-Based Spacial Clustering of Applications With Noise. \n\nOne problem with some of the other clustering algorithms is that they only work well when the clusters are separate and compact. Noise and outliers can cause problems with other clustering methods. In real life datasets clusters could be arbitrary shapes and have noise and as we can see below DBSCAN is sometimes needed to be used instead of other clustering models such as K-Means. \n\n![](PicsArt_11-17-08.07.10-300x300.jpg)\n\n**DBSCAN Algorithm**\n\n1. Define Parameters\n\n-**eps** is the maximum distance between two points in order for them to be considered neighbors. If eps is too small, many points will be labeled as outliers, and if eps is too large we will not have definition in our clusters. We can use the k-distance graph to find our eps value.\n\n-**MinPts** is the minimum number of neighbors within the eps radius. A general rule is MinPts >= number of dimensions in the dataset + 1. The minimum value of MinPts is 3.\n\n2. Find all neighbor points within eps and identify core points - the points that have more than MinPts within its eps radius. \n\n3. For each core point if it has not been assigned a cluster, create a new cluster with that point.\n\n4. Find all density-connected points to the core point and assign to the same cluster. Two points are density-connected if there is a core point that contains both points within its eps radius. \n\n5. Points that do not belong to a cluster are considered noise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(factoextra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n:::\n\n```{.r .cell-code}\n# set random seed to make reproducable results \nset.seed(123456789)\n\n# extract x and y coordinates\nmultishapes <- multishapes[, 1:2]\nplot(multishapes)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nLet's see how K-Means would cluster this dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm_res <- kmeans(multishapes, 5, nstart = 25)\nplot(multishapes, col=km_res$cluster+1, main=\"K-means\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\nNow let's see if DBSCAN does a better job\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dbscan)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dbscan'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    as.dendrogram\n```\n:::\n\n```{.r .cell-code}\ndbscan_res <- dbscan(multishapes, eps = 0.15, minPts = 5)\nplot(multishapes, col=dbscan_res$cluster+1, main=\"DBSCAN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}