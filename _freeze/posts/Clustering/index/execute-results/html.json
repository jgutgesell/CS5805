{
  "hash": "4a5289f5006ac25e312cd135355dc8f2",
  "result": {
    "markdown": "---\ntitle: \"Clustering\"\nauthor: \"Julia Gutgesell\"\ndate: \"2023-11-18\"\n---\n\n\nClustering is an unsupervised learning method that divides data points into a number of groups based on similar properties. There are multiple different clustering methods vary in the distance calculations to determine the clusters. Some of these algorithms are:\n\n-   K-Means\n-   Affinity Propagation\n-   Mean-Shift\n-   DBSCAN\n-   Gaussian Mixtures\n-   Spectral Clustering\n\nWe will focus on DBSCAN - Density-Based Spacial Clustering of Applications With Noise.\n\nOne problem with some of the other clustering algorithms is that they only work well when the clusters are separate and compact. Noise and outliers can cause problems with other clustering methods. In real life datasets clusters could be arbitrary shapes and have noise and as we can see below DBSCAN is sometimes needed to be used instead of other clustering models such as K-Means.\n\n![](PicsArt_11-17-08.07.10-300x300.jpg)\n\nClusters are inherently high-density areas of space that are surrounded by lower-density space. When humans look at images we can identify the clusters easily, but some of these models go based on pure distance instead of looking at density and this is where DBSCAN can be especially useful in cases with more complex shapes and noise.\n\n**DBSCAN Algorithm**\n\n1.  Define Parameters\n\n-   **Epsilon (eps)** is the maximum distance between two points in order for them to be considered neighbors. If epsilon is too small, many points will be labeled as outliers, and if epsilon is too large we will not have definition in our clusters. We can use the k-distance graph to find our epsilon value.\n\n-   **Minimum Points (MinPts)** is the minimum number of neighbors within the epsilon radius. The minimum value of MinPts is 3, but as the dataset gets larger our MinPts paramter should also get larger.\n\n2.  Find all neighbor points within eps and identify core points - the points that have more than MinPts within its eps radius.\n\n3.  For each core point if it has not been assigned a cluster, create a new cluster with that point.\n\n4.  Find all density-connected points to the core point and assign to the same cluster. Two points are density-connected if there is a core point that contains both points within its eps radius.\n\n5.  Points that do not belong to a cluster are considered noise.\n\n**Example with Code**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(factoextra)\n\n# set random seed to make reproducable results \nset.seed(123456789)\n\n# extract x and y coordinates\nmultishapes <- multishapes[, 1:2]\nplot(multishapes)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nIn this plot we can see that there are 5 different clusters: 2 ovals at the top of the image, 2 lines at the bottom left, and one dense cluster at the bottom right.\n\n**Let's see how K-Means would cluster this dataset:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm_res <- kmeans(multishapes, 5, nstart = 25)\nplot(multishapes, col=km_res$cluster+1, main=\"K-means\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nWe can see that this may not be the best possible clusters. We would expect to see the circles be one cluster each not split into to 3 different clusters across the 2 circles. K-Means did not separate the 2 lines into different clusters either.\n\n**Now let's see if DBSCAN does a better job:**\n\nFirst we must decide our value of eps using the k-distance plot. We set k=5 since we are going to use minPts=5. The value of eps we want to use is where the elbow of the graph is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dbscan)\nkNNdistplot(multishapes, k=5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nWe see that our elbow is below 0.2, so we will use eps=0.15 for our inital DBSCAN algorithm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbscan_res <- dbscan(multishapes, eps = 0.15, minPts = 5)\nplot(multishapes, col=dbscan_res$cluster+1, main=\"DBSCAN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nNow the clusters look much more like how we would have expected. We also see the noisy points in black are not part of any cluster.\n\n**Parameter Effects**\n\nLet's see first hand how changing our 2 parameters effect the clusters we find.\n\n1.  **Smaller eps**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbscan_res <- dbscan(multishapes, eps = 0.05, minPts = 5)\nplot(multishapes, col=dbscan_res$cluster+1, main=\"DBSCAN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWe see way too many of our points are outliers.\n\n2.  **Larger eps**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbscan_res <- dbscan(multishapes, eps = 0.45, minPts = 5)\nplot(multishapes, col=dbscan_res$cluster+1, main=\"DBSCAN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nWith the larger eps value we now only have 2 clusters, meaning we lose a lot of the details of our points.\n\n3.  **Larger minPts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbscan_res <- dbscan(multishapes, eps = 0.15, minPts = 7)\nplot(multishapes, col=dbscan_res$cluster+1, main=\"DBSCAN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nNow we have a situation where there are now too many clusters and it is more complicated than is necessary.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}