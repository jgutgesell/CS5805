---
title: "Probability Theory and Random Variables"
author: "Julia Gutgesell"
date: "2023-11-21"
---

Probability theory is an important aspect of many machine learning algorithms since in reality there are very few things that we know with complete certainty.

Two important properties of probability are that probabilities are between 0 and 1, with 0 being impossible and 1 being certain, and that the some of all probabilities of an event have to equal 1.

![](axioms.png)

To describe the probabilities that random variable $x$ can take on each specific outcome of the event we can use a **probability distribution**. There are two different types of probability distributions: discrete and continuous.

**Discrete Distributions**

Discrete distributions are when the outcomes are finite like heads or tails of a coin. A Bernoulli distribution is an example of a discrete distribution where there are only 2 potential outcomes. The probability mass function of a Bernoulli distribution of a fair coin flip is P(x) = {0.5 if x = heads, 0.5 if x = tails}.

**Continuous Distributions**

Continuous distributions have infinitely many outcomes, for example heights. One well known continuous distribution is the normal distribution which can be visualized with the bell curve.

```{r echo=FALSE}
x <- seq(-4, 4, .01)
#calculate normal CDF probabilities
density <- dnorm(x)
 #plot normal PDF
plot(x, density, type="l", main = "Normal Distribution Curve")
```

Unlike discrete distributions where the value of the probability mass function at $x$ is the probability of of $x$, in the continuous distribution since there are infinitely many outcomes the probability of X = $x$ is actually 0. All of our probabilities must sum to 1, when looking at the normal distribution curve that means that the area under the curve must also be 1. So instead of using a summation, we look at intervals in the continuous case.

![](integral.png)

So instead of looking at the probability of an event at a specific value which we now know is 0, we can use ranges of X and calculate the area under the curve for those ranges to find meaningful probabilities in the continuous case. We can use something called the cumulative distribution function which takes the probability density function we saw above and calculates the area under the curve to the left of $x$. This is what the CDF of the normal distribution looks like:

```{r echo=FALSE}
x <- seq(-4, 4, .01)
#calculate normal CDF probabilities
density <- pnorm(x)
 #plot normal PDF
plot(x, density, type="l", main = "Normal Cumulative Distribution")
```

Now we can see probabilities much easier such as $P(x < -3)$ is nearly 0 and $P(x < 3)$ is nearly 1.

**Conditional Probability Distributions**

In order to understand Bayes' Rule we first must understand conditional probabilities. Oftentimes, the probabilities we are interested in are dependent on another event. The conditional probability of **x given y** is:

![](conditional.png)

By multiplying by $P(y)$ we get the **chain rule** of probability: $P(x,y) = P(x|y) P(y)$

**Bayesian Probability and Bayes' Rule**

A well known probability philosophy is **Bayesian Probability**. Unlike an objective perspective where known beliefs are used, a subjective perspective where the observer's own learnings and experience are used, Bayesian probability combines prior beliefs with observations. We can use Bayes' Rule to calculate our probabilities.

Back to our chain rule, we can write equivalent statments

-   $P(x,y) = P(x|y) P(y)$
-   $P(x,y) = P(y|x) P(x)$

If we set these to be equal and divide by $P(y)$ we get Bayes' Rule:

![](Bayes.png)

This rule allows us update our beliefs as we gain more observations. The prior probability, which is what initial probability of an event, and the posterior probability is the probability after adding in our new observation.

**Naive Bayes**

Naive Bayes use Bayes' Rule but with a couple key assumptions:

-   Predictors are conditionally independent
-   All features contribute equally to the outcome

Although this may not lead to the most complete and accurate model in real life, it allows us to simplify the problem.

```{r message=FALSE}
library(caret)
library(e1071)
library(caTools)
```

```{r}
# split data into train and test splits
set.seed(222)
index <- sample(2, nrow(iris), replace = TRUE, prob = c(0.7, 0.3))
train <- iris[index==1,]
test <- iris[index==2,]

```

```{r}
bayes <- naiveBayes(Species ~ ., data = train)
bayes
```

We see that our Naive Bayes function calculates our prior probabilities and the conditional probabilities for our predictors.

```{r}
prediction <- predict(bayes, newdata = test)

confusion <- table(test$Species, prediction)
confusionMatrix(confusion)
```

We see that we get a model accuracy of 95% which is very good.

**Images used can be found [here](https://towardsdatascience.com/probability-fundamentals-of-machine-learning-part-1-a156b4703e69)**
